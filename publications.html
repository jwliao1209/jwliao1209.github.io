<!DOCTYPE HTML>

<html>
	<head>
		<title>Publications</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">
		<div id="page-wrapper">

			<!-- Header -->
			<header id="header">
				<h1><a href="index.html">Jiawei</a></h1>
				<nav id="nav">
					<ul>
						<li><a href="index.html" target="_blank">Home</a></li>
						<li><a href="publications.html" class="button">Publications</a></li>
						<li><a href="projects.html">Projects</a></li>
						<li><a href="talks.html">Talks</a></li>
						<li><a href="teaching.html">Teaching</a></li>
						<li><a href="activities.html">Activities</a></li>
					</ul>
				</nav>
			</header>


			<!-- Main -->
			<section id="main" class="container publications-page">
				<header>
					<h2>Publications</h2>
				</header>

				<div class="row">
					<div class="col-12">
						<div id="filter-container">
							<h3>Tags</h3>
							<div class="filter-row">
								<div id="filter-tags"></div>
							</div>
						</div>

						<div class="publications-container">
							<section class="publication-card box" data-tags="#Diffusion Models, #Guidance">
								<h4 class="publication-title">DiffRGD: A Training-Free Diffusion Guidance Through Riemannian Gradient Descent</h4>
								<p class="publication-authors">
									<b>Jia-Wei Liao</b>,
									<a href="https://alexpeng517.github.io/">Li-Xuan Peng</a>,
									<a href="https://math.ntnu.edu.tw/~yueh/">Mei-Heng Yueh</a>,
									<a href="https://aliensunmin.github.io/">Min Sun</a>,
									<a href="https://www.csie.ntu.edu.tw/~ccf/">Cheng-Fu Chou</a>,
									<a href="https://homepage.citi.sinica.edu.tw/pages/pullpull/index_en.html">Jun-Cheng Chen</a>
								</p>
								<p class="publication-venue">In submission</p>
								<div class="tags-container"></div>
							</section>

							<section class="publication-card box" data-tags="#Diffusion Models, #Attack">
								<div class="publication-split">
									<div class="publication-main">
										<h4 class="publication-title">M-ErasureBench: A Comprehensive Multimodal Evaluation Benchmark for Concept Erasure in Diffusion Models</h4>
										<p class="publication-authors">
											Ju-Hsuan Weng*,
											<b>Jia-Wei Liao</b>*,
											<a href="https://www.csie.ntu.edu.tw/~ccf/">Cheng-Fu Chou</a>,
											<a href="https://homepage.citi.sinica.edu.tw/pages/pullpull/index_en.html">Jun-Cheng Chen</a>
										</p>
										<p class="publication-venue">WACV 2026</p>
										<div class="tags-container"></div>
										<div class="button-container">
											<li><a href="https://arxiv.org/abs/2512.22877" class="custom-button" target="_blank">Paper</a></li>
											<li><a href="projects/wacv26_m-erasurebench/slides.pdf" class="custom-button" target="_blank">Slides</a></li>
											<li><a href="projects/wacv26_m-erasurebench/poster.pdf" class="custom-button" target="_blank">Poster</a></li>
										</div>
										<details class="publication-abs-collapsible">
											<summary class="publication-abs-toggle">TL;DR</summary>
											<p class="publication-abs">M-ErasureBench is a multimodal benchmark revealing that existing diffusion concept-erasure methods fail beyond text prompts and introduces an inference-time module that significantly improves erasure robustness without retraining.</p>
										</details>
									</div>
									<div class="publication-media">
										<div class="youtube-video">
											<div class="videobox">
												<iframe src="https://www.youtube.com/embed/iD2dgTkljjI?si=_13QIja-AzMr7FsL" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
											</div>
										</div>
									</div>
								</div>
							</section>

							<section class="publication-card box" data-tags="#Diffusion Models, #Guidance">
								<h4 class="publication-title">Zero-shot Geometry-Aware Diffusion Guidance for Music Restoration</h4>
								<p class="publication-authors">
									<b>Jia-Wei Liao</b>,
									Pin-Chi Pan,
									<a href="https://alexpeng517.github.io/">Li-Xuan Peng</a>,
									Sheng-Ping Yang,
									<a href="https://ytsrt66589.github.io/">Yen-Tung Yeh</a>,
									<a href="https://www.csie.ntu.edu.tw/~ccf/">Cheng-Fu Chou</a>,
									<a href="https://affige.github.io/">Yi-Hsuan Yang</a>
								</p>
								<p class="publication-venue">NeurIPS 2025 AI4Music Workshop</p>
								<div class="tags-container"></div>
								<div class="button-container">
									<li><a href="https://openreview.net/forum?id=pKmjzw8TO8" class="custom-button" target="_blank">Paper</a></li>
									<li><a href="projects/neuripsw2025_dgg.pdf" class="custom-button" target="_blank">Poster</a></li>
								</div>
								<details class="publication-abs-collapsible">
									<summary class="publication-abs-toggle">TL;DR</summary>
									<p class="publication-abs">Diffusion Geodesic Guidance (DGG) is a zero-shot geometry-aware diffusion guidance method that updates samples along hyperspherical geodesics to preserve the model prior while improving music restoration quality without retraining.</p>
								</details>
							</section>

							<section class="publication-card box" data-tags="#Segmentation">
								<h4 class="publication-title">BEVAN: Bilateral Efficient Visual Attention Network for Real-Time Semantic Segmentation</h4>
								<p class="publication-authors">
									Ping-Mao Huang,
									I-Tien Chao,
									Ping-Chia Huang,
									<b>Jia-Wei Liao</b>,
									<a href="https://www.csie.ntu.edu.tw/~cyy/">Yung-Yu Chuang</a>
								</p>
								<p class="publication-venue">ICIP 2025</p>
								<div class="tags-container"></div>
								<div class="button-container">
									<li><a href="https://arxiv.org/abs/2508.07300" class="custom-button" target="_blank">Paper</a></li>
									<li><a href="https://github.com/maomao0819/BEVANet" class="custom-button" target="_blank">Code</a></li>
								</div>
								<details class="publication-abs-collapsible">
									<summary class="publication-abs-toggle">TL;DR</summary>
									<p class="publication-abs">BEVANet is a bilateral large-kernel attention network that achieves state-of-the-art real-time semantic segmentation by adaptively expanding receptive fields and fusing semantic, structural, and boundary features efficiently.</p>
								</details>
							</section>

						<section class="publication-card box" data-tags="#Diffusion Models, #Guidance">
							<div class="publication-split">
								<div class="publication-main">
									<h4 class="publication-title">DiffQRCoder: Diffusion-based Aesthetic QR Code Generation with Scanning Robustness Guided Iterative Refinement</h4>
									<p class="publication-authors">
										<b>Jia-Wei Liao</b>,
										<a href="https://dinoslow.github.io/">Winston Wang</a>*,
										Tzu-Sian Wang*,
										<a href="https://alexpeng517.github.io/">Li-Xuan Peng</a>*,
										Ju-Hsuan Weng,
										<a href="https://www.csie.ntu.edu.tw/~ccf/">Cheng-Fu Chou</a>,
										<a href="https://homepage.citi.sinica.edu.tw/pages/pullpull/index_en.html">Jun-Cheng Chen</a>
									</p>
									<p class="publication-venue">WACV 2025</p>
									<div class="tags-container"></div>
									<div class="button-container">
										<li><a href="https://arxiv.org/abs/2409.06355" class="custom-button" target="_blank">Paper</a></li>
										<li><a href="https://github.com/jwliao1209/DiffQRCoder" class="custom-button" target="_blank">Code</a></li>
										<li><a href="https://jwliao1209.github.io/DiffQRCoder/" class="custom-button" target="_blank">Project Page</a></li>
										<li><a href="https://jwliao1209.github.io/DiffQRCoder/_astro/slides.ClYDGbgS.pdf" class="custom-button" target="_blank">Slides</a></li>
										<li><a href="https://jwliao1209.github.io/DiffQRCoder/_astro/poster.Dia1PEDY.pdf" class="custom-button" target="_blank">Poster</a></li>
									</div>
									<details class="publication-abs-collapsible">
										<summary class="publication-abs-toggle">TL;DR</summary>
										<p class="publication-abs">DiffQRCoder is a training-free diffusion framework that generates visually appealing QR codes while preserving high scanning robustness through geometry-aware perceptual guidance and iterative refinement.</p>
									</details>
								</div>
								<div class="publication-media">
									<div class="youtube-video">
										<div class="videobox">
											<iframe src="https://www.youtube.com/embed/rIuBahFrBdI?si=Z_YTOxZnJgbMK_XJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
										</div>
									</div>
								</div>
							</div>
						</section>

						<section class="publication-card box" data-tags="#Diffusion Models, #Attack">
							<div class="publication-split">
								<div class="publication-main">
									<h4 class="publication-title">Pixel Is Not A Barrier: An Effective Evasion Attack for Pixel-Domain Diffusion Models</h4>
									<p class="publication-authors">
										Chun-Yen Shih*,
										<a href="https://alexpeng517.github.io/">Li-Xuan Peng</a>*,
										<b>Jia-Wei Liao</b>,
										<a href="https://www.cs.jhu.edu/~schu23/">Ernie Chu</a>,
										<a href="https://www.csie.ntu.edu.tw/~ccf/">Cheng-Fu Chou</a>,
										<a href="https://homepage.citi.sinica.edu.tw/pages/pullpull/index_en.html">Jun-Cheng Chen</a>
									</p>
									<p class="publication-venue">AAAI 2025</p>
									<div class="tags-container"></div>
									<div class="button-container">
										<li><a href="https://arxiv.org/abs/2408.11810" class="custom-button" target="_blank">Paper</a></li>
										<li><a href="https://github.com/AlexPeng517/AtkPDM" class="custom-button" target="_blank">Code</a></li>
										<li><a href="https://alexpeng517.github.io/AtkPDM/" class="custom-button" target="_blank">Project Page</a></li>
										<li><a href="https://alexpeng517.github.io/AtkPDM/_astro/slides.CoPlVrhE.pdf" class="custom-button" target="_blank">Slides</a></li>
										<li><a href="https://alexpeng517.github.io/AtkPDM/_astro/poster.BtAsMwQa.pdf" class="custom-button" target="_blank">Poster</a></li>
									</div>
									<details class="publication-abs-collapsible">
										<summary class="publication-abs-toggle">TL;DR</summary>
										<p class="publication-abs">AtkPDM is a feature-space adversarial attack framework that crafts imperceptible perturbations to protect images from unauthorized diffusion-based editing by disrupting UNet representations while preserving visual fidelity.</p>
									</details>
								</div>
								<div class="publication-media">
									<div class="youtube-video">
										<div class="videobox">
											<iframe src="https://www.youtube.com/embed/fhxMVybGf9s?si=LCz-nZfz5C5UIoJR" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
										</div>
									</div>
								</div>
							</div>
						</section>

							<section class="publication-card box" data-tags="#Active Learning, #Detection">
								<h4 class="publication-title">Distribution Discrepancy and Feature Heterogeneity for Active 3D Object Detection</h4>
								<p class="publication-authors">
									Huang-Yu Chen,
									<a href="https://www.cmlab.csie.ntu.edu.tw/~jiafongyeh/">Jia-Fong Yeh</a>,
									<b>Jia-Wei Liao</b>,
									Pin-Hsuan Peng,
									<a href="https://winstonhsu.info/">Winston H Hsu</a>
								</p>
								<p class="publication-venue">CoRL 2024</p>
								<div class="tags-container"></div>
								<div class="button-container">
									<li><a href="https://arxiv.org/abs/2409.05425" class="custom-button" target="_blank">Paper</a></li>
									<li><a href="https://github.com/Coolshanlan/DDFH-active-3Ddet" class="custom-button" target="_blank">Code</a></li>
								</div>
								<details class="publication-abs-collapsible">
									<summary class="publication-abs-toggle">TL;DR</summary>
									<p class="publication-abs">DDFH is an active learning framework for LiDAR-based 3D object detection that selects the most informative samples by jointly modeling distribution discrepancy and feature heterogeneity to reduce annotation cost while improving detection performance.</p>
								</details>
							</section>

							<section class="publication-card box" data-tags="#Medical AI, #Segmentation">
								<div class="publication-split">
									<div class="publication-main">
									<h4 class="publication-title">An UNet-Based Brain Tumor Segmentation Framework via Optimal Mass Transportation Pre-processing</h4>
									<p class="publication-authors">
										<b>Jia-Wei Liao</b>,
										<a href="https://sites.google.com/gapps.ntnu.edu.tw/tmhuang">Tsung-Ming Huang</a>,
										Tiexiang Li,
										<a href="https://sites.google.com/g2.nctu.edu.tw/wwlin">Wen-Wei Lin</a>,
										Han Wang,
										<a href="https://daweb.qzc.tsinghua.edu.cn/ShingTungYau/en/zdylm/5539/list/index.htm">Shing-Tung Yau</a>
									</p>
									<p class="publication-venue">MICCAI 2022 Brainlesion Workshop</p>
									<div class="tags-container"></div>
									<div class="button-container">
										<li><a href="https://link.springer.com/chapter/10.1007/978-3-031-33842-7_19" class="custom-button" target="_blank">Paper</a></li>
									</div>
									<details class="publication-abs-collapsible">
										<summary class="publication-abs-toggle">TL;DR</summary>
										<p class="publication-abs">This paper proposes a two-phase UNet-based brain tumor segmentation framework that uses optimal mass transportation to enlarge tumor regions and enhance data diversity, significantly improving MRI segmentation accuracy and robustness.</p>
									</details>
								</div>
								<div class="publication-media">
									<div class="youtube-video">
										<div class="videobox">
											<iframe src="https://www.youtube.com/embed/T6q67Iyo-Ec?si=5AysuRO6NQffj0SB" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
										</div>
									</div>
							</section>
						</div>
					</div>
				</div>
			</section>

			<!-- Footer -->
			<footer id="footer">
				<ul class="copyright">
					<li>&copy; 2026 Jiawei. All rights reserved.</li>
				</ul>
			</footer>

		</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.dropotron.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

			<script>
				document.querySelectorAll(".publication-card").forEach(box => {
					const tagsContainer = box.querySelector(".tags-container");
					const tags = box.getAttribute("data-tags").split(", ");
					tags.forEach(tag => {
						const span = document.createElement("span");
						span.className = "tags";
						span.textContent = tag;
						tagsContainer.appendChild(span);
					});
				});

				const uniqueTags = new Set();
				document.querySelectorAll(".publication-card").forEach(box => {
					const tags = box.getAttribute("data-tags").split(", ");
					tags.forEach(tag => uniqueTags.add(tag));
				});
		
				const filterTagsContainer = document.getElementById("filter-tags");
				uniqueTags.forEach(tag => {
					const tagButton = document.createElement("span");
					tagButton.className = "filter-tags";
					tagButton.textContent = tag.replace(/^#/, "");
					tagButton.setAttribute("data-tag", tag);
					filterTagsContainer.appendChild(tagButton);
				});

				const selectedTags = new Set();
				document.addEventListener("click", function (e) {
					if (e.target.classList.contains("filter-tags")) {
						const tag = e.target.getAttribute("data-tag");

						if (selectedTags.has(tag)) {
							selectedTags.delete(tag);
							e.target.classList.remove("selected");
						} else {
							selectedTags.add(tag);
							e.target.classList.add("selected");
						}
						filterPublications();
					}
				});

				function filterPublications() {
					const publications = document.querySelectorAll(".publication-card");
					publications.forEach(publication => {
						const tags = publication.getAttribute("data-tags").split(", ");
						if (selectedTags.size === 0) {
							publication.style.display = "block";
						} else {
							const match = Array.from(selectedTags).some(tag => tags.includes(tag));
							publication.style.display = match ? "block" : "none";
						}
					});
				}
			</script>
	</body>
</html>
