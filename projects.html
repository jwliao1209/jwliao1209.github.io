<!DOCTYPE HTML>
<!--
	Alpha by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Talks</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">
		<div id="page-wrapper">

			<!-- Header -->
				<header id="header">
					<h1><a href="index.html">Jiawei's</a> Website</h1>
					<nav id="nav">
						<ul>
							<li><a href="index.html">Home</a></li>
							<li><a href="projects.html">Projects</a></li>
							<li><a href="talks.html">Talks</a></li>
							<li><a href="activities.html">Activities</a></li>
							<li><a href="teaching.html">Teaching</a></li>
							<li><a href="files/jiawei_cv.pdf" class="button" target="_blank">Download CV</a></li>
						</ul>
					</nav>
				</header>


			<!-- Main -->
				<section id="main" class="container">
					<header>
						<h2>Selected Projects</h2>
					</header>
					<div class="row">
						<div class="col-12">

							<!-- ADL final -->
                            <section class="box">
                                <h3>Taiwan-LLM Tutor: Revolutionizing Taiwanese Secondary Education with Large Language Model</h3>
                                <p><b>Jia-Wei Liao</b>, Ji-Jia Wu, Kun-Hsiang Lin, and Kang-Yang Huang, Applied Deep Learning Final Project, 2022.</p>
								<ul class="actions small">
									<li><a href="projects/twllm_tutor_slides.pdf" class="button alt small" target="_blank">Slides</a></li>
									<li><a href="https://github.com/jwliao1209/TWLLM-Tutor" class="button alt small" target="_blank">Code</a></li>
								</ul>
								</p>
                            </section>

							<section class="box">
                                <h3>Multimodal Pathological Voice Classification</h3>
                                <p>Chun-Hsien Chen, Shu-Cheng Zheng, <b>Jia-Wei Liao</b>, and Yi-Cheng Hung, AICUP, 2023</p>
								<ul class="actions small">
									<li><a href="projects/multimodal_pathological_voice_classification_report.pdf" class="button alt small" target="_blank">Report</a></li>
									<li><a href="https://github.com/jwliao1209/Multimodal-Pathological-Voice-Classification" class="button alt small" target="_blank">Code</a></li>
								</ul>
                            </section>

                            <section class="box">
                                <h3>A Small Object Detection Framework for Unmanned Aerial Vehicles Images</h3>
                                <p>Jing-En Huang and <b>Jia-Wei Liao</b>, AI CUP, 2022.</p>
								<ul class="actions small">
									<li><a href="projects/a_small_object_detection_framework_for_uav_images_report.pdf" class="button alt small" target="_blank">Report</a></li>
								</ul>

								<div style="display: flex; align-items: center; justify-content: center; flex-wrap: wrap;">
									<div style="flex: 3; display: flex; justify-content: center; align-items: center;">
										<p>
											We developed a state-of-the-art one-stage detection model as the baseline framework for the competition, with the goal of accurately detecting small objects. To enhance performance, we utilized data relabeling, super-resolution, and a small object augmentation algorithm. Additionally, we employed the sliding window technique to reduce computation complexity and improve training speed. Post-processing techniques such as TTA, NMS, and WBF were also implemented to further improve model performance. As a result, we achieved a top 5 ranking in the competition with a public score of 0.7394 and a private score of 0.7550.
										</p>
									</div>
									<div style="flex: 2; display: flex; justify-content: center;">
										<img src="images/a_small_object_detection_framework_for_uav_images_image.jpeg" alt="" style="height: 280px;"/>
									</div>
								</div>

                            </section>

							<section class="box">
                                <h3>Optimizing Marketing Strategies and Data Analysis for Bag Brand</h3>
                                <p>Yi-Jhen Ciou, I-Ting Wang, Kai Yu, and <b>Jia-Wei Liao</b>, TMBA Final Project, 2023</p>
                            </section>

                            <section class="box">
                                <h3>Crop Image Recognition</h3>
                                <p><b>Jia-Wei Liao</b>, Yen-Jia Chen, Yi-Cheng Hung, Jing-En Hung, and Shang-Yen Lee, AI CUP, 2022.</p>
								<ul class="actions small">
									<li><a href="projects/crop_image_recognition_report.pdf" class="button alt small" target="_blank">Report</a></li>
									<li><a href="https://github.com/jwliao1209/Crop-Image-Recognition" class="button alt small" target="_blank">Code</a></li>
								</ul>

								<div style="display: flex; align-items: center; justify-content: center; flex-wrap: wrap;">
									<div style="flex: 3; display: flex; justify-content: center; align-items: center;">
										<p>
											We explored various models, applied auto-augmentation techniques to diversify the dataset, and trained with CNN base models like EfficientNet and Transformer-base models like Swin. Our results showed that using SGD as the optimizer had better convergence than AdamW and higher image resolution led to better training performance. We found that the Swin model performed better on lower resolution data while CNN base models performed better on high resolution data. To evaluate the stability and advantage of ensemble combination, we applied TTA and ensemble to both public and private datasets. As a result, we achieved a public ranking of 9th and a private ranking of 8th, with scores of 0.9329 and 0.9344 respectively.
										</p>
									</div>
									<div style="flex: 2; display: flex; justify-content: center;">
										<img src="images/crop_image_recognition_image.png" alt="" style="height: 250px;"/>
									</div>
								</div>
                            </section>

							<section class="box">
                                <h3>Explainable Information Tagging for Natural Language Understanding</h3>
                                <p><b>Jia-Wei Liao</b>, Jung-Mei Chu, and Chia-Chi Huang, AI CUP, 2022.</p>
								<ul class="actions small">
									<li><a href="projects/explainable _information_tagging_for_natural_language_understanding_report.pdf" class="button alt small" target="_blank">Report</a></li>
									<li><a href="https://github.com/jwliao1209/Explainable-NLP" class="button alt small" target="_blank">Code</a></li>
								</ul>
								<p>We constructed an explainable deep learning model for a NLP task by converting it into a summary task. Initially we used a LSTM model but switched to T5 with pretrained weights to achieve better results. We applied the T5 model to two datasets with different pre-processing methods and surpassed the original data's baseline. We achieved a public score of 0.801772 and a private score of 0.85190.</p>
                            </section>

							<section class="box">
                                <h3>Contour Segmentation for Spread Through Air Spaces in Lung Adenocarcinoma</h3>
                                <p><b>Jia-Wei Liao</b>, Kuok-Tong Ng, and Yi-Cheng Hung, AI CUP, 2022.</p>
								<ul class="actions small">
									<li><a href="projects/aicup_2022_stas_report.pdf" class="button alt small" target="_blank">Report</a></li>
									<li><a href="https://github.com/jwliao1209/STAS-Segmentation" class="button alt small" target="_blank">Code</a></li>
								</ul>

								<div style="display: flex; align-items: center; justify-content: center; flex-wrap: wrap;">
									<div style="flex: 3; display: flex; justify-content: center; align-items: center;">
										<p>
											We developed a UNet-based model with a diverse backbone, addressing the imbalance of foreground and background through a combination of DiceLoss and Focal Loss, and enhancing robustness through auto-augmentation. Our post-processing strategies improved accuracy, resulting in a 3rd place public ranking and 16th place private ranking, with scores of 0.9194 and 0.9109 respectively.
										</p>
									</div>
									<div style="flex: 2; display: flex; justify-content: center;">
										<img src="images/aicup_2022_stas_image.jpg" alt="" style="height: 160px;"/>
									</div>
								</div>
                            </section>

							<section class="box">
                                <h3>Supervised Learning for Few-Shot Orchid types Classification with Prior Guided Feature</h3>
                                <p>Yu-Hsi Chen, <b>Jia-Wei Liao</b>, and Kuok-Tong Ng, AI CUP, 2022.</p>
								<ul class="actions small">
									<li><a href="projects/supervised_learning_for_few_shot_orchid_types_classification_with_prior_guided_feature_report.pdf" class="button alt small" target="_blank">Report</a></li>
									<li><a href="https://github.com/jwliao1209/Orchid-Classification" class="button alt small" target="_blank">Code</a></li>
								</ul>

								<div style="display: flex; align-items: center; justify-content: center; flex-wrap: wrap;">
									<div style="flex: 3; display: flex; justify-content: center; align-items: center;">
										<p>
											We develop a non-artificial method for accurately distinguishing orchids with similar appearances. Orchids are a diverse group of plants with over 20,000 species found in various ecological environments, except for extreme climates. However, advancements in biotechnology have led to the creation of similar new species, making it difficult for experts to distinguish them. Due to the lack of training data, we employed a few-shot learning approach to transfer information from one task and generalize to a new task with a small amount of data. We used various models, data augmentation methods, training objective functions, optimization methods, and learning rate schedules in our approach. After multiple trials, we ensemble the six predictions with the highest accuracy to obtain the final predictions. Our method achieved a Marco-F1 score of 0.9115 and 0.8096 on public and private datasets, respectively, and ranked 15th out of 743 teams in the competition.
										</p>
									</div>
									<div style="flex: 2; display: flex; justify-content: center;">
										<img src="images/supervised_learning_for_few_shot_orchid_types_classification_with_prior_guided_feature_image.png" alt="" style="height: 250px;"/>
									</div>
								</div>
                            </section>

							<section class="box">
                                <h3>MediaTek Low-power Segmentation Competition</h3>
                                <p><b>Jia-Wei Liao</b>, Machine Learning Final Project, 2022.</p>
								<ul class="actions small">
									<li><a href="https://github.com/jwliao1209/Low-Power-Segmentation" class="button alt small" target="_blank">Code</a></li>
								</ul>
								<div style="display: flex; align-items: center; justify-content: center; flex-wrap: wrap;">
									<div style="flex: 3; display: flex; justify-content: center; align-items: center;">
										<p>
											We propose a lightweight deep learning-based semantic segmentation model that is suitable for constrained embedded systems and is optimized for traffic scene analysis in Asian countries, such as Taiwan. The model focuses on improving segmentation accuracy, reducing power consumption, and achieving real-time performance. The model is also designed to be deployed on MediaTek's Dimensity Series platform. The evaluation metric used is mean Intersection over Union (mIoU) which is a widely used metric for multi-class semantic segmentation tasks. Our experiments yielded a test public score of 0.5624.
										</p>
									</div>
									<div style="flex: 2; display: flex; justify-content: center;">
										<img src="images/low_power_segmentation_image.png" alt="" style="height: 250px;"/>
									</div>
								</div>
                            </section>

							<section class="box">
                                <h3>Ultrasound Nerve Segmentation</h3>
                                <p><b>Jia-Wei Liao</b>, Kuok-Tong Ng, and Yi-Cheng Hung, VRDL Final Project (Kaggle), 2021</p>
								<ul class="actions small">
									<li><a href="projects/ultrasound_nerve_segmentation_report.pdf" class="button alt small" target="_blank">Report</a></li>
									<li><a href="https://github.com/jwliao1209/Ultrasound-Nerve-Segmentation" class="button alt small" target="_blank">Code</a></li>
								</ul>
								<div style="display: flex; align-items: center; justify-content: center; flex-wrap: wrap;">
									<div style="flex: 3; display: flex; justify-content: center; align-items: center;">
										<p>
											We present a deep learning-based approach for ultrasound nerve segmentation using the UNet architecture with the EfficientNet backbone. Two novel methods, Erosion Mask Smoothing (ELS) and adaptive Single Model Ensemble (ASME) were proposed to improve the segmentation performance. The evaluation metric used is the Dice Similarity Coefficient (DSC), and the results show that the proposed approach outperforms the baseline with a test private score of 0.7234, achieved through the use of ASME.
										</p>
									</div>
									<div style="flex: 2; display: flex; justify-content: center;">
										<img src="images/ultrasound_nerve_segmentation_image.png" alt="" style="height: 180px;"/>
									</div>
								</div>
                            </section>

							<section class="box">
                                <h3>Low Rank Matrix Factorization for Recommender System</h3>
                                <p><b>Jia-Wei Liao</b>, Kuok-Tong Ng, and Yi-Cheng Hung, Introduction to Scientific Computing Final Project, 2021</p>
								<ul class="actions small">
									<li><a href="projects/low_rank_matrix_factorization_for_recommender_system.pdf" class="button alt small" target="_blank">Report</a></li>
									<li><a href="https://github.com/jwliao1209/softImpute-ALS" class="button alt small" target="_blank">Code</a></li>
								</ul>
                            </section>

							<section class="box">
                                <h3>Sentiment Analysis of Food Reviews on Yelp Platform</h3>
                                <p><b>Jia-Wei Liao</b>, Yi-Cheng Hung, and Yu-Lin Tsai, Introduction to Data Science Final Project, 2021</p>
								<ul class="actions small">
									<li><a href="projects/sentiment_analysis_of_reviews_on_yelp_platform.pdf" class="button alt small" target="_blank">Report</a></li>
								</ul>
                            </section>

							<section class="box">
                                <h3>Solving the Biharmonic Equation by Deep Neural Network</h3>
                                <p><b>Jia-Wei Liao</b>, Yu-Hsi Chen, and Woan-Rong Huang, Numerical Partial Differential Equations Final Project, 2021</p>
								<ul class="actions small">
									<li><a href="projects/solving_the_biharmonic_equation_by_deep_neural_network.pdf" class="button alt small" target="_blank">Slides</a></li>
									<li><a href="https://github.com/jwliao1209/3D-Animation-Morphing" class="button alt small" target="_blank">Code</a></li>
								</ul>
                            </section>

							<section class="box">
                                <h3>3D Shape Morphing Animation based on Poisson Image Editing</h3>
                                <p><b>Jia-Wei Liao</b> and Kuok-Tong Ng, 3D Computationl Geometry Final Project, 2021</p>
								<ul class="actions small">
									<li><a href="projects/sentiment_analysis_of_reviews_on_yelp_platform.pdf" class="button alt small" target="_blank">Code</a></li>
								</ul>
                            </section>

							<section class="box">
                                <h3>Mean Curvature Flow on Graphs for Image Denoising</h3>
                                <p><b>Jia-Wei Liao</b> and Kuok-Tong Ng, Image Processing with Partial Differential Equations Final Project, 2020</p>
								<ul class="actions small">
									<li><a href="projects/on_the_mean_curvature_flow_on_graphs_with _applications_in_image_and_manifold_processing.pdf" class="button alt small" target="_blank">Report</a></li>
									<li><a href="https://github.com/jwliao1209/Mean-Curvature-Flow" class="button alt small" target="_blank">Code</a></li>
								</ul>
                            </section>

							<section class="box">
                                <h3>Online Dictionary Learning for Image Inpainting</h3>
                                <p><b>Jia-Wei Liao</b> and Kuok-Tong Ng, Optimization for Data Science Final Project, 2020</p>
								<ul class="actions small">
									<li><a href="projects/online_dictionary_learning_for_image_inpainting_slides.pdf" class="button alt small" target="_blank">Report</a></li>
									<li><a href="https://github.com/jwliao1209/Online-Dictionary-Learning" class="button alt small" target="_blank">Code</a></li>
								</ul>
                            </section>

							<section class="box">
                                <h3>Variational Models and Numerical Methods for Image Processing</h3>
                                <p><b>Jia-Wei Liao</b>, Chun-Hsien Chen, and Chen-Yang Dai, NCTS-USRP Final Project, 2020</p>
								<ul class="actions small">
									<li><a href="projects/2020_ncts_usrp_report.pdf" class="button alt small" target="_blank">Report</a></li>
									<li><a href="projects/2020_ncts_usrp_slides.pdf" class="button alt small" target="_blank">Slides</a></li>
									<li><a href="https://github.com/jwliao1209/Total-Variational-Model" class="button alt small" target="_blank">Code</a></li>
								</ul>
                            </section>
							
							
						</div>
					</div>
				</section>

			<!-- Footer -->
				<footer id="footer">
					<ul class="copyright">
						<li>&copy; Untitled. All rights reserved.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
					</ul>
				</footer>

		</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.dropotron.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>